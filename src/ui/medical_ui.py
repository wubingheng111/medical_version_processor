import streamlit as st
from PIL import Image
import numpy as np
import cv2
from datetime import datetime
from typing import Dict, List, Optional, Any, Callable
import os
import io

class MedicalUI:
    """åŒ»å­¦å½±åƒå¤„ç†ç³»ç»ŸUIç®¡ç†å™¨"""
    
    def __init__(self, systems: Dict):
        """åˆå§‹åŒ–UIç®¡ç†å™¨
        
        Args:
            systems: åŒ…å«å„ä¸ªç³»ç»Ÿç»„ä»¶çš„å­—å…¸
        """
        self.systems = systems
        self._init_session_state()
        self._setup_styles()
        self.current_mode = 'manual'  # 'manual' or 'workflow'
        self.current_image = None
        self.current_results = None
        
        # åˆå§‹åŒ–VLMæ¨¡å‹
        if 'smart_diagnosis' in self.systems:
            self.systems['smart_diagnosis'].initialize_vlm()
    
    def _init_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if 'processed_image' not in st.session_state:
            st.session_state.processed_image = None
        if 'original_image' not in st.session_state:
            st.session_state.original_image = None
        if 'processing_history' not in st.session_state:
            st.session_state.processing_history = []
        if 'redo_history' not in st.session_state:
            st.session_state.redo_history = []
        if 'current_params' not in st.session_state:
            st.session_state.current_params = {}
        if 'last_analysis' not in st.session_state:
            st.session_state.last_analysis = None
    
    def _setup_styles(self):
        """è®¾ç½®UIæ ·å¼"""
        st.markdown("""
            <style>
            /* å…¨å±€æ ·å¼ */
            .main {
                padding: 0rem 1rem;
                background-color: #1a1a1a;
                color: #e0e0e0;
            }
            
            /* æ ‡é¢˜æ ·å¼ */
            .main-title {
                color: #ffffff;
                text-align: center;
                padding: 1rem;
                margin-bottom: 2rem;
                background: linear-gradient(120deg, #2c5282, #1a365d);
                border-radius: 10px;
                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
            }
            
            /* å¡ç‰‡æ ·å¼ */
            .stCard {
                background-color: #2d3748;
                padding: 1.5rem;
                border-radius: 10px;
                box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
                margin-bottom: 1rem;
                border: 1px solid #4a5568;
                color: #e0e0e0;
            }
            </style>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        with st.sidebar:
            st.markdown("""
                <div style='text-align: center; padding: 1rem;'>
                    <h2 style='color: white;'>MedVision Pro</h2>
                    <p style='color: #a8b9cc;'>æ™ºèƒ½åŒ»å­¦å½±åƒåˆ†æå¹³å°</p>
                </div>
            """, unsafe_allow_html=True)
            
            # è‡ªåŠ¨åˆ†æé€‰é¡¹
            st.markdown("---")
            auto_analyze = st.checkbox("ğŸ”„ å¤„ç†åè‡ªåŠ¨åˆ†æ", value=False)
            st.session_state.auto_analyze = auto_analyze
            
            # åŠŸèƒ½é€‰æ‹©
            st.markdown("### ğŸ› ï¸ åŠŸèƒ½é€‰æ‹©")
            operation = st.selectbox(
                "é€‰æ‹©å¤„ç†åŠŸèƒ½",
                ["å›¾åƒé¢„å¤„ç†", "å›¾åƒå¢å¼º", "å›¾åƒåˆ†å‰²", "é«˜çº§å¤„ç†", "æ™ºèƒ½è¯Šæ–­", "è¿œç¨‹åä½œ", "è´¨é‡æ§åˆ¶"],
                format_func=lambda x: {
                    "å›¾åƒé¢„å¤„ç†": "âš™ï¸ å›¾åƒé¢„å¤„ç†",
                    "å›¾åƒå¢å¼º": "âœ¨ å›¾åƒå¢å¼º",
                    "å›¾åƒåˆ†å‰²": "âœ‚ï¸ å›¾åƒåˆ†å‰²",
                    "é«˜çº§å¤„ç†": "ğŸ”§ é«˜çº§å¤„ç†",
                    "æ™ºèƒ½è¯Šæ–­": "ğŸ¥ æ™ºèƒ½è¯Šæ–­",
                    "è¿œç¨‹åä½œ": "ğŸ‘¥ è¿œç¨‹åä½œ",
                    "è´¨é‡æ§åˆ¶": "ğŸ“Š è´¨é‡æ§åˆ¶"
                }[x]
            )
            
            return operation
    
    def render_main_content(self, operation: str):
        """æ¸²æŸ“ä¸»è¦å†…å®¹"""
        st.markdown("""
            <div class='main-title'>
                <h1>MedVision Pro</h1>
                <p style='font-size: 1.2rem; opacity: 0.8;'>åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½åŒ»å­¦å½±åƒå¤„ç†ä¸åˆ†æç³»ç»Ÿ</p>
            </div>
        """, unsafe_allow_html=True)
        
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        uploaded_file = self.render_upload_section()
        
        if uploaded_file is not None:
            self.handle_uploaded_file(uploaded_file, operation)
    
    def render_upload_section(self):
        """æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ"""
        st.markdown("""
            <div style='text-align: center; padding: 2rem; background: #2d3748; border-radius: 10px; border: 2px dashed #4a5568; margin: 20px 0;'>
                <h3 style='color: #90cdf4; margin-bottom: 10px;'>ğŸ“ é€‰æ‹©åŒ»å­¦å›¾åƒæ–‡ä»¶</h3>
                <p style='color: #718096; font-size: 0.9em;'>æ”¯æŒæ ¼å¼: JPG, PNG, DICOM, NIfTI</p>
                <p style='color: #718096; font-size: 0.9em;'>æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„æˆ–ç‚¹å‡»é€‰æ‹©</p>
            </div>
        """, unsafe_allow_html=True)
        
        return st.file_uploader("", type=["jpg", "png", "dcm", "nii.gz"])
    
    def handle_uploaded_file(self, uploaded_file, operation: str):
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        try:
            # è¯»å–å¹¶æ˜¾ç¤ºåŸå§‹å›¾åƒ
            image = Image.open(uploaded_file)
            image_copy = image.copy()
            image.close()
            st.session_state.original_image = image_copy
            
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ç”¨äºæ˜¾ç¤ºå›¾åƒ
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                    <div class='image-container'>
                        <h3 style='color: #2c3e50; margin-bottom: 1rem;'>ğŸ“· åŸå§‹å›¾åƒ</h3>
                    </div>
                """, unsafe_allow_html=True)
                st.image(image_copy, use_container_width=True)
            
            with col2:
                st.markdown("""
                    <div class='image-container'>
                        <h3 style='color: #2c3e50; margin-bottom: 1rem;'>ğŸ”„ å¤„ç†ç»“æœ</h3>
                    </div>
                """, unsafe_allow_html=True)
                if st.session_state.processed_image is not None:
                    st.image(st.session_state.processed_image, use_container_width=True)
            
            # æ ¹æ®é€‰æ‹©çš„åŠŸèƒ½æ˜¾ç¤ºä¸åŒçš„å¤„ç†é€‰é¡¹
            if operation == "å›¾åƒé¢„å¤„ç†":
                self.render_preprocessing_options()
            elif operation == "å›¾åƒå¢å¼º":
                self.render_enhancement_options()
            elif operation == "å›¾åƒåˆ†å‰²":
                self.render_segmentation_options()
            elif operation == "é«˜çº§å¤„ç†":
                self.render_advanced_options()
            elif operation == "æ™ºèƒ½è¯Šæ–­":
                self.render_diagnosis_options()
            elif operation == "è¿œç¨‹åä½œ":
                self.render_collaboration_options()
            elif operation == "è´¨é‡æ§åˆ¶":
                self.render_quality_control_options()
            
        except Exception as e:
            st.error(f"é”™è¯¯ï¼š{str(e)}")
    
    def render_preprocessing_options(self):
        """æ¸²æŸ“å›¾åƒé¢„å¤„ç†é€‰é¡¹"""
        st.subheader("å›¾åƒé¢„å¤„ç†")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ç°åº¦è½¬æ¢"):
                self.handle_grayscale_conversion()
        
        with col2:
            if st.button("ç›´æ–¹å›¾å‡è¡¡åŒ–"):
                self.handle_histogram_equalization()
    
    def render_enhancement_options(self):
        """æ¸²æŸ“å›¾åƒå¢å¼ºé€‰é¡¹"""
        st.subheader("å›¾åƒå¢å¼º")
        
        if st.session_state.original_image is not None:
            contrast = st.slider("å¯¹æ¯”åº¦è°ƒæ•´", 0.1, 3.0, 1.0)
            brightness = st.slider("äº®åº¦è°ƒæ•´", -100, 100, 0)
            
            if st.button("åº”ç”¨å¢å¼º"):
                self.handle_image_enhancement(contrast, brightness)
    
    def render_segmentation_options(self):
        """æ¸²æŸ“å›¾åƒåˆ†å‰²é€‰é¡¹"""
        st.subheader("å›¾åƒåˆ†å‰²")
        
        if st.session_state.original_image is not None:
            method = st.selectbox(
                "é€‰æ‹©åˆ†å‰²æ–¹æ³•",
                ["è¾¹ç¼˜æ£€æµ‹", "åŒºåŸŸç”Ÿé•¿", "åˆ†æ°´å²­ç®—æ³•"]
            )
            
            if st.button("æ‰§è¡Œåˆ†å‰²"):
                self.handle_image_segmentation(method)
    
    def render_diagnosis_options(self):
        """æ¸²æŸ“æ™ºèƒ½è¯Šæ–­é€‰é¡¹"""
        st.subheader("æ™ºèƒ½è¯Šæ–­")
        
        if st.session_state.original_image is not None:
            # é€‰æ‹©åˆ†ææ¨¡å¼
            analysis_mode = st.radio(
                "é€‰æ‹©åˆ†ææ¨¡å¼",
                ["æ‰‹åŠ¨æ¨¡å¼", "å·¥ä½œæµæ¨¡å¼"],
                format_func=lambda x: {
                    "æ‰‹åŠ¨æ¨¡å¼": "ğŸ”§ æ‰‹åŠ¨æ¨¡å¼ï¼ˆè‡ªå®šä¹‰å‚æ•°ï¼‰",
                    "å·¥ä½œæµæ¨¡å¼": "ğŸ”„ å·¥ä½œæµæ¨¡å¼ï¼ˆè‡ªåŠ¨åŒ–å¤„ç†ï¼‰"
                }[x]
            )
            
            if analysis_mode == "æ‰‹åŠ¨æ¨¡å¼":
                # åŸæœ‰çš„æ‰‹åŠ¨åˆ†æåŠŸèƒ½
                analysis_type = st.selectbox(
                    "é€‰æ‹©åˆ†æç±»å‹",
                    ["lesion_detection", "organ_segmentation", "measurement"],
                    format_func=lambda x: {
                        "lesion_detection": "ç—…å˜æ£€æµ‹",
                        "organ_segmentation": "å™¨å®˜åˆ†å‰²",
                        "measurement": "å…³é”®æŒ‡æ ‡æµ‹é‡"
                    }[x]
                )
                
                # æ·»åŠ å‚æ•°è°ƒæ•´æ»‘å—
                with st.expander("é«˜çº§å‚æ•°è®¾ç½®"):
                    if analysis_type == "lesion_detection":
                        confidence_threshold = st.slider(
                            "ç½®ä¿¡åº¦é˜ˆå€¼",
                            min_value=0.1,
                            max_value=0.9,
                            value=0.4,
                            step=0.1
                        )
                        min_area = st.slider(
                            "æœ€å°åŒºåŸŸæ¯”ä¾‹",
                            min_value=0.0001,
                            max_value=0.01,
                            value=0.001,
                            format="%.4f"
                        )
                        max_area = st.slider(
                            "æœ€å¤§åŒºåŸŸæ¯”ä¾‹",
                            min_value=0.01,
                            max_value=0.5,
                            value=0.3
                        )
                        
                        custom_params = {
                            'confidence_threshold': confidence_threshold,
                            'min_area_ratio': min_area,
                            'max_area_ratio': max_area
                        }
                    else:
                        custom_params = {}
                
                if st.button("å¼€å§‹åˆ†æ", key="manual_analysis"):
                    self.handle_smart_diagnosis(analysis_type, custom_params)
            
            else:  # å·¥ä½œæµæ¨¡å¼
                # é€‰æ‹©å›¾åƒç±»å‹
                image_type = st.selectbox(
                    "é€‰æ‹©å›¾åƒç±»å‹",
                    ["ct", "mri", "xray"],
                    format_func=lambda x: {
                        "ct": "CTæ‰«æ",
                        "mri": "æ ¸ç£å…±æŒ¯",
                        "xray": "Xå…‰ç‰‡"
                    }[x]
                )
                
                # é€‰æ‹©åˆ†æç›®æ ‡
                analysis_goal = st.selectbox(
                    "é€‰æ‹©åˆ†æç›®æ ‡",
                    ["lesion_detection", "organ_segmentation"],
                    format_func=lambda x: {
                        "lesion_detection": "ç—…å˜æ£€æµ‹",
                        "organ_segmentation": "å™¨å®˜åˆ†å‰²"
                    }[x]
                )
                
                # è·å–æ¨èå·¥ä½œæµ
                workflow = self.systems['smart_workflow'].get_recommended_workflow(
                    image_type=image_type,
                    analysis_goal=analysis_goal
                )
                
                if 'error' not in workflow:
                    # æ˜¾ç¤ºå·¥ä½œæµä¿¡æ¯
                    with st.expander("æŸ¥çœ‹å·¥ä½œæµè¯¦æƒ…"):
                        st.json(workflow['workflow'])
                    
                    # æ‰§è¡Œå·¥ä½œæµ
                    if st.button("å¼€å§‹åˆ†æ", key="workflow_analysis"):
                        with st.spinner("æ­£åœ¨æ‰§è¡Œå·¥ä½œæµ..."):
                            result = self.systems['smart_workflow'].execute_workflow(
                                workflow_name=workflow['workflow']['name'],
                                input_image=st.session_state.original_image
                            )
                            
                            if 'error' not in result:
                                st.success("åˆ†æå®Œæˆï¼")
                                # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
                                self.display_workflow_results(result['execution_result'])
                            else:
                                st.error(f"åˆ†æå¤±è´¥: {result['error']}")
                else:
                    st.error(f"è·å–å·¥ä½œæµå¤±è´¥: {workflow['error']}")
        else:
            st.error("è¯·å…ˆä¸Šä¼ å›¾åƒ")
    
    def handle_smart_diagnosis(self, analysis_type: str, custom_params: Dict = None):
        """å¤„ç†æ™ºèƒ½è¯Šæ–­"""
        try:
            if st.session_state.original_image is not None:
                with st.spinner("æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æ..."):
                    # ä½¿ç”¨VLMè¿›è¡Œåˆæ­¥åˆ†æ
                    vlm_result = self.systems['smart_diagnosis'].vlm_analyzer.analyze_image(
                        st.session_state.original_image,
                        analysis_type
                    )
                    
                    # ç»“åˆVLMåˆ†æç»“æœå’Œè‡ªå®šä¹‰å‚æ•°è¿›è¡Œæœ€ç»ˆåˆ†æ
                    result = self.systems['smart_diagnosis'].analyze_image(
                        st.session_state.original_image,
                        analysis_type,
                        custom_params=custom_params,
                        vlm_analysis=vlm_result.get('analysis', {})
                    )
                    
                    if 'error' not in result:
                        st.success("åˆ†æå®Œæˆï¼")
                        self.display_diagnosis_results(result, analysis_type, vlm_result)
                    else:
                        st.error(f"åˆ†æå¤±è´¥: {result['error']}")
            else:
                st.error("è¯·å…ˆä¸Šä¼ å›¾åƒ")
        except Exception as e:
            st.error(f"æ™ºèƒ½è¯Šæ–­å¤±è´¥: {str(e)}")
    
    def display_diagnosis_results(self, result: Dict, analysis_type: str, vlm_result: Dict = None):
        """æ˜¾ç¤ºè¯Šæ–­ç»“æœ"""
        # åˆ›å»ºé€‰é¡¹å¡
        tabs = st.tabs(["æ£€æµ‹ç»“æœ", "VLMåˆ†æ", "è¯¦ç»†ä¿¡æ¯"])
        
        # æ£€æµ‹ç»“æœé€‰é¡¹å¡
        with tabs[0]:
            col1, col2 = st.columns(2)
            with col1:
                st.write("### åŸå§‹å›¾åƒ")
                st.image(st.session_state.original_image, use_column_width=True)
            with col2:
                st.write("### åˆ†æç»“æœ")
                if analysis_type == "lesion_detection" and 'lesions' in result:
                    annotated_image = self.systems['smart_diagnosis'].draw_lesions(
                        st.session_state.original_image,
                        result['lesions'],
                        result['confidence_scores']
                    )
                    st.image(annotated_image, use_column_width=True)
        
        # VLMåˆ†æé€‰é¡¹å¡
        with tabs[1]:
            if vlm_result and 'analysis' in vlm_result:
                st.write("### VLMæ¨¡å‹åˆ†æç»“æœ")
                st.write(vlm_result['analysis'])
                if 'suggestions' in vlm_result:
                    st.write("### å»ºè®®")
                    for suggestion in vlm_result['suggestions']:
                        st.info(suggestion)
            else:
                st.info("æ— VLMåˆ†æç»“æœ")
        
        # è¯¦ç»†ä¿¡æ¯é€‰é¡¹å¡
        with tabs[2]:
            if analysis_type == "lesion_detection" and 'lesions' in result:
                st.write("### æ£€æµ‹åˆ°çš„ç—…å˜")
                for i, lesion in enumerate(result['lesions']):
                    with st.expander(f"ç—…å˜ {i+1} (ç½®ä¿¡åº¦: {result['confidence_scores'][i]:.2%})"):
                        st.write(f"- ä½ç½®: {lesion['bbox']}")
                        st.write(f"- é¢ç§¯: {lesion['area']:.2f}")
                        st.write(f"- ä¸­å¿ƒç‚¹: {lesion['centroid']}")
                        if 'circularity' in lesion:
                            st.write(f"- åœ†å½¢åº¦: {lesion['circularity']:.2f}")
                        
                        # æ˜¾ç¤ºå…¶ä»–ç‰¹å¾
                        if 'features' in lesion:
                            st.write("### ç—…å˜ç‰¹å¾")
                            for feature, value in lesion['features'].items():
                                st.metric(feature, f"{value:.2f}")
    
    def render_collaboration_options(self):
        """æ¸²æŸ“è¿œç¨‹åä½œé€‰é¡¹"""
        st.subheader("è¿œç¨‹åä½œ")
        
        if st.session_state.original_image is not None:
            if st.button("åˆ›å»ºåä½œä¼šè¯"):
                self.handle_collaboration_session()
    
    def render_quality_control_options(self):
        """æ¸²æŸ“è´¨é‡æ§åˆ¶é€‰é¡¹"""
        st.subheader("è´¨é‡æ§åˆ¶")
        
        if st.session_state.original_image is not None:
            if st.button("è¯„ä¼°å›¾åƒè´¨é‡"):
                self.handle_quality_assessment()
    
    def handle_grayscale_conversion(self):
        """å¤„ç†ç°åº¦è½¬æ¢"""
        try:
            if st.session_state.original_image is not None:
                processed = self.systems['image_processor'].to_grayscale(
                    st.session_state.original_image
                )
                st.session_state.processed_image = processed
                self.add_to_history("ç°åº¦è½¬æ¢")
                st.rerun()
            else:
                st.error("è¯·å…ˆä¸Šä¼ å›¾åƒ")
        except Exception as e:
            st.error(f"ç°åº¦è½¬æ¢å¤±è´¥: {str(e)}")
    
    def handle_histogram_equalization(self):
        """å¤„ç†ç›´æ–¹å›¾å‡è¡¡åŒ–"""
        try:
            if st.session_state.original_image is not None:
                processed = self.systems['image_processor'].histogram_equalization(
                    st.session_state.original_image
                )
                st.session_state.processed_image = processed
                self.add_to_history("ç›´æ–¹å›¾å‡è¡¡åŒ–")
                st.rerun()
            else:
                st.error("è¯·å…ˆä¸Šä¼ å›¾åƒ")
        except Exception as e:
            st.error(f"ç›´æ–¹å›¾å‡è¡¡åŒ–å¤±è´¥: {str(e)}")
    
    def handle_image_enhancement(self, contrast: float, brightness: int):
        """å¤„ç†å›¾åƒå¢å¼º"""
        try:
            if st.session_state.original_image is not None:
                processed = self.systems['image_processor'].adjust_contrast_brightness(
                    st.session_state.original_image,
                    contrast=contrast,
                    brightness=brightness
                )
                st.session_state.processed_image = processed
                self.add_to_history("å›¾åƒå¢å¼º", {
                    'contrast': contrast,
                    'brightness': brightness
                })
                st.rerun()
            else:
                st.error("è¯·å…ˆä¸Šä¼ å›¾åƒ")
        except Exception as e:
            st.error(f"å›¾åƒå¢å¼ºå¤±è´¥: {str(e)}")
    
    def handle_image_segmentation(self, method: str):
        """å¤„ç†å›¾åƒåˆ†å‰²"""
        try:
            if st.session_state.original_image is not None:
                if method == "è¾¹ç¼˜æ£€æµ‹":
                    processed = self.systems['image_processor'].edge_detection(
                        st.session_state.original_image
                    )
                elif method == "åŒºåŸŸç”Ÿé•¿":
                    # ä½¿ç”¨å›¾åƒä¸­å¿ƒç‚¹ä½œä¸ºç§å­ç‚¹
                    h, w = np.array(st.session_state.original_image).shape[:2]
                    seed_point = (w//2, h//2)
                    processed = self.systems['image_processor'].region_growing(
                        st.session_state.original_image,
                        seed_point
                    )
                elif method == "åˆ†æ°´å²­ç®—æ³•":
                    processed = self.systems['image_processor'].watershed_segmentation(
                        np.array(st.session_state.original_image)
                    )
                    processed = Image.fromarray(processed)
                
                st.session_state.processed_image = processed
                self.add_to_history("å›¾åƒåˆ†å‰²", {'method': method})
                st.rerun()
            else:
                st.error("è¯·å…ˆä¸Šä¼ å›¾åƒ")
        except Exception as e:
            st.error(f"å›¾åƒåˆ†å‰²å¤±è´¥: {str(e)}")
    
    def handle_collaboration_session(self):
        """å¤„ç†åä½œä¼šè¯"""
        try:
            session = self.systems['collaboration'].create_session(
                session_name=f"Session_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                creator_id="current_user"
            )
            if 'error' not in session:
                st.success(f"ä¼šè¯åˆ›å»ºæˆåŠŸï¼ID: {session['id']}")
                st.session_state.current_session = session
            else:
                st.error(f"åˆ›å»ºä¼šè¯å¤±è´¥: {session['error']}")
        except Exception as e:
            st.error(f"åˆ›å»ºåä½œä¼šè¯å¤±è´¥: {str(e)}")
    
    def handle_quality_assessment(self):
        """å¤„ç†è´¨é‡è¯„ä¼°"""
        try:
            if st.session_state.original_image is not None:
                with st.spinner("æ­£åœ¨è¯„ä¼°å›¾åƒè´¨é‡..."):
                    result = self.systems['quality_control'].assess_image_quality(
                        st.session_state.original_image
                    )
                    
                    if 'success' in result:
                        self.display_quality_results(result)
                    else:
                        st.error(f"è¯„ä¼°å¤±è´¥: {result['error']}")
            else:
                st.error("è¯·å…ˆä¸Šä¼ å›¾åƒ")
        except Exception as e:
            st.error(f"è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")
    
    def display_workflow_results(self, execution_result: Dict):
        """æ˜¾ç¤ºå·¥ä½œæµæ‰§è¡Œç»“æœ"""
        # åˆ›å»ºé€‰é¡¹å¡
        tabs = st.tabs(["å¤„ç†ç»“æœ", "ä¸­é—´ç»“æœ", "æ‰§è¡Œç»Ÿè®¡"])
        
        # å¤„ç†ç»“æœé€‰é¡¹å¡
        with tabs[0]:
            col1, col2 = st.columns(2)
            with col1:
                st.write("### åŸå§‹å›¾åƒ")
                st.image(st.session_state.original_image, use_column_width=True)
            with col2:
                st.write("### æœ€ç»ˆç»“æœ")
                if execution_result['final_image'] is not None:
                    st.image(execution_result['final_image'], use_column_width=True)
        
        # ä¸­é—´ç»“æœé€‰é¡¹å¡
        with tabs[1]:
            for step_id, result in execution_result['intermediate_results'].items():
                with st.expander(f"æ­¥éª¤ {step_id}"):
                    # æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
                    if 'processed_image' in result:
                        st.image(result['processed_image'], use_column_width=True)
                    
                    # æ˜¾ç¤ºå¤„ç†å‚æ•°
                    if 'parameters' in result:
                        st.write("ä½¿ç”¨çš„å‚æ•°ï¼š")
                        st.json(result['parameters'])
                    
                    # æ˜¾ç¤ºè´¨é‡æŒ‡æ ‡
                    if 'metrics' in result:
                        st.write("è´¨é‡æŒ‡æ ‡ï¼š")
                        for metric, value in result['metrics'].items():
                            st.metric(metric, f"{value:.2f}")
        
        # æ‰§è¡Œç»Ÿè®¡é€‰é¡¹å¡
        with tabs[2]:
            # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
            start_time = datetime.fromisoformat(execution_result['started_at'])
            end_time = datetime.fromisoformat(execution_result['completed_at'])
            execution_time = (end_time - start_time).total_seconds()
            
            # æ˜¾ç¤ºæ‰§è¡Œç»Ÿè®¡
            st.metric("æ€»æ‰§è¡Œæ—¶é—´", f"{execution_time:.2f}ç§’")
            st.metric("å¤„ç†æ­¥éª¤æ•°", len(execution_result['steps_executed']))
            
            # æ˜¾ç¤ºæ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œæ—¶é—´
            st.write("### æ­¥éª¤æ‰§è¡Œæ—¶é—´")
            for i, step in enumerate(execution_result['steps_executed']):
                step_time = datetime.fromisoformat(step['executed_at'])
                if i > 0:
                    prev_time = datetime.fromisoformat(
                        execution_result['steps_executed'][i-1]['executed_at']
                    )
                    step_duration = (step_time - prev_time).total_seconds()
                else:
                    step_duration = (step_time - start_time).total_seconds()
                
                st.metric(
                    f"æ­¥éª¤ {step['step_id']} ({step['step_type']})",
                    f"{step_duration:.2f}ç§’"
                )
    
    def display_quality_results(self, result: Dict):
        """æ˜¾ç¤ºè´¨é‡è¯„ä¼°ç»“æœ"""
        st.write("### è´¨é‡è¯„ä¼°ç»“æœ")
        metrics = result['metrics']
        assessment = result['assessment']
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("å¯¹æ¯”åº¦", f"{metrics['contrast']:.2f}")
            st.metric("äº®åº¦", f"{metrics['brightness']:.2f}")
            st.metric("æ¸…æ™°åº¦", f"{metrics['sharpness']:.2f}")
        with col2:
            st.metric("å™ªå£°æ°´å¹³", f"{metrics['noise_level']:.2f}")
            st.metric("ä¿¡å™ªæ¯”", f"{metrics['snr']:.2f}")
        
        st.write("### æ”¹è¿›å»ºè®®")
        for metric, assess in assessment.items():
            if assess['status'] != 'good':
                st.warning(f"- {assess['recommendation']}")
    
    def add_to_history(self, operation: str, params: Dict = None):
        """æ·»åŠ æ“ä½œåˆ°å¤„ç†å†å²"""
        try:
            if st.session_state.processed_image is None:
                raise ValueError("å¤„ç†åçš„å›¾åƒä¸å¯ç”¨")
            
            processed_image = st.session_state.processed_image
            if not isinstance(processed_image, Image.Image):
                if isinstance(processed_image, np.ndarray):
                    if len(processed_image.shape) == 2:
                        processed_image = Image.fromarray(processed_image, 'L')
                    elif len(processed_image.shape) == 3:
                        if processed_image.shape[2] == 4:
                            processed_image = Image.fromarray(processed_image, 'RGBA')
                        else:
                            processed_image = Image.fromarray(processed_image, 'RGB')
                else:
                    raise ValueError("æ— æ³•å°†å›¾åƒè½¬æ¢ä¸ºPIL Imageæ ¼å¼")
            
            processed_image_copy = processed_image.copy()
            
            st.session_state.processing_history.append({
                'operation': operation,
                'params': params or {},
                'image': processed_image_copy
            })
            
            st.session_state.processed_image = processed_image_copy
            st.session_state.current_params = params or {}
            st.session_state.last_analysis = None
            st.session_state.redo_history = []
            
        except Exception as e:
            st.error(f"æ·»åŠ å¤„ç†å†å²å¤±è´¥: {str(e)}")
            st.info("è¯·æ£€æŸ¥å›¾åƒå¤„ç†æ˜¯å¦æˆåŠŸå®Œæˆã€‚")

    def setup_sidebar(self):
        """è®¾ç½®ä¾§è¾¹æ """
        st.sidebar.title('åŒ»å­¦å›¾åƒå¤„ç†ç³»ç»Ÿ')
        
        # æ¨¡å¼é€‰æ‹©
        self.current_mode = st.sidebar.radio(
            'é€‰æ‹©æ“ä½œæ¨¡å¼',
            ['æ‰‹åŠ¨æ¨¡å¼', 'å·¥ä½œæµæ¨¡å¼'],
            format_func=lambda x: 'æ‰‹åŠ¨æ¨¡å¼' if x == 'manual' else 'å·¥ä½œæµæ¨¡å¼'
        )
        
        st.sidebar.markdown('---')
        
        # å›¾åƒä¸Šä¼ 
        uploaded_file = st.sidebar.file_uploader(
            'ä¸Šä¼ åŒ»å­¦å›¾åƒ',
            type=['png', 'jpg', 'jpeg', 'dicom']
        )
        
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file)
                self.current_image = np.array(image)
                st.sidebar.success('å›¾åƒä¸Šä¼ æˆåŠŸ')
            except Exception as e:
                st.sidebar.error(f'å›¾åƒåŠ è½½å¤±è´¥: {str(e)}')
    
    def show_manual_mode(self, image_processor, smart_diagnosis):
        """æ˜¾ç¤ºæ‰‹åŠ¨æ¨¡å¼ç•Œé¢"""
        if self.current_image is None:
            st.info('è¯·å…ˆä¸Šä¼ å›¾åƒ')
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader('åŸå§‹å›¾åƒ')
            st.image(self.current_image, use_column_width=True)
            
            # å›¾åƒå¤„ç†å‚æ•°
            st.subheader('å›¾åƒå¤„ç†å‚æ•°')
            brightness = st.slider('äº®åº¦', -100, 100, 0)
            contrast = st.slider('å¯¹æ¯”åº¦', 0.1, 3.0, 1.0)
            detail_enhancement = st.slider('ç»†èŠ‚å¢å¼º', 0.0, 2.0, 1.0)
            
            if st.button('åº”ç”¨å¤„ç†'):
                # åº”ç”¨å›¾åƒå¤„ç†
                result = image_processor.adjust_brightness_contrast(
                    self.current_image,
                    brightness=brightness,
                    contrast=contrast
                )
                if result['success']:
                    enhanced_result = image_processor.enhance_details(
                        result['image'],
                        strength=detail_enhancement
                    )
                    if enhanced_result['success']:
                        self.current_results = enhanced_result
                        st.success('å¤„ç†å®Œæˆ')
                    else:
                        st.error(enhanced_result['error'])
                else:
                    st.error(result['error'])
        
        with col2:
            st.subheader('å¤„ç†ç»“æœ')
            if self.current_results and 'image' in self.current_results:
                st.image(self.current_results['image'], use_column_width=True)
            
            # VLMåˆ†æ
            st.subheader('VLMåˆ†æ')
            prompt = st.text_input('è¾“å…¥åˆ†ææç¤º', 'æ£€æµ‹å›¾åƒä¸­çš„å¼‚å¸¸åŒºåŸŸ')
            
            if st.button('å¼€å§‹åˆ†æ'):
                with st.spinner('æ­£åœ¨åˆ†æ...'):
                    result = smart_diagnosis.analyze_with_vlm(
                        self.current_image,
                        prompt=prompt
                    )
                    if result['success']:
                        st.success(f"åˆ†æå®Œæˆï¼Œç›¸ä¼¼åº¦: {result['similarity']:.2f}")
                    else:
                        st.error(result['error'])
    
    def show_workflow_mode(self, workflow_system):
        """æ˜¾ç¤ºå·¥ä½œæµæ¨¡å¼ç•Œé¢"""
        if self.current_image is None:
            st.info('è¯·å…ˆä¸Šä¼ å›¾åƒ')
            return
        
        st.subheader('å·¥ä½œæµæ¨¡å¼')
        
        # è·å–å·¥ä½œæµæ¨¡æ¿
        templates = workflow_system.get_workflow_templates()
        if not templates['success']:
            st.error('è·å–å·¥ä½œæµæ¨¡æ¿å¤±è´¥')
            return
        
        # é€‰æ‹©å·¥ä½œæµæ¨¡æ¿
        template_names = {
            'lesion_detection': 'ç—…å˜æ£€æµ‹å·¥ä½œæµ',
            'organ_segmentation': 'å™¨å®˜åˆ†å‰²å·¥ä½œæµ',
            'quality_optimization': 'å›¾åƒè´¨é‡ä¼˜åŒ–å·¥ä½œæµ'
        }
        
        selected_template = st.selectbox(
            'é€‰æ‹©å·¥ä½œæµæ¨¡æ¿',
            list(template_names.keys()),
            format_func=lambda x: template_names[x]
        )
        
        if st.button('æ‰§è¡Œå·¥ä½œæµ'):
            with st.spinner('æ­£åœ¨æ‰§è¡Œå·¥ä½œæµ...'):
                # åˆ›å»ºå·¥ä½œæµ
                workflow = workflow_system.create_workflow(
                    name=template_names[selected_template],
                    template_id=selected_template
                )
                
                if not workflow['success']:
                    st.error('åˆ›å»ºå·¥ä½œæµå¤±è´¥')
                    return
                
                # æ‰§è¡Œå·¥ä½œæµ
                context = {
                    'image': self.current_image,
                    'workflow_id': workflow['workflow']['id']
                }
                
                result = workflow_system.execute_workflow(
                    workflow['workflow']['id'],
                    context
                )
                
                if result['success']:
                    st.success('å·¥ä½œæµæ‰§è¡Œå®Œæˆ')
                    
                    # æ˜¾ç¤ºç»“æœ
                    for step_result in result['results']:
                        with st.expander(f"æ­¥éª¤: {step_result['step']}"):
                            if step_result['success']:
                                if 'image' in step_result['result']:
                                    st.image(
                                        step_result['result']['image'],
                                        use_column_width=True
                                    )
                                st.json(step_result['result'])
                            else:
                                st.error(step_result['error'])
                else:
                    st.error(result['error'])
    
    def show_results(self, results: Dict[str, Any]):
        """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
        if not results:
            return
        
        st.subheader('å¤„ç†ç»“æœ')
        
        # æ˜¾ç¤ºå›¾åƒç»“æœ
        if 'image' in results:
            st.image(results['image'], use_column_width=True)
        
        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
        if 'lesions' in results:
            st.subheader(f"æ£€æµ‹åˆ° {len(results['lesions'])} ä¸ªç—…å˜åŒºåŸŸ")
            for i, lesion in enumerate(results['lesions']):
                with st.expander(f"ç—…å˜åŒºåŸŸ {i+1}"):
                    st.json(lesion)
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        if 'analysis' in results:
            st.subheader('åˆ†æç»“æœ')
            st.json(results['analysis'])
    
    def show_error(self, error: str):
        """æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯"""
        st.error(f"é”™è¯¯: {error}")
    
    def show_success(self, message: str):
        """æ˜¾ç¤ºæˆåŠŸä¿¡æ¯"""
        st.success(message)
    
    def get_current_image(self) -> np.ndarray:
        """è·å–å½“å‰å›¾åƒ"""
        return self.current_image
    
    def get_current_mode(self) -> str:
        """è·å–å½“å‰æ¨¡å¼"""
        return self.current_mode 